{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UH4PzMVUiFHX"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import random\n",
        "import sklearn\n",
        "import sklearn.datasets\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from cvxpy import *\n",
        "from scipy import stats\n",
        "from scipy import sparse\n",
        "from scipy import linalg\n",
        "from scipy.linalg import eigh\n",
        "from scipy.sparse import linalg\n",
        "from scipy.sparse import csr_array\n",
        "from scipy.sparse import coo_array\n",
        "from scipy.sparse import csr_matrix\n",
        "from scipy.sparse.linalg import eigs, eigsh\n",
        "from sklearn.preprocessing import normalize\n",
        "from sklearn.metrics.cluster import adjusted_rand_score\n",
        "from sklearn.metrics.pairwise import euclidean_distances"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sigma_mat(dist, k):\n",
        "  dist.sort(axis=1)\n",
        "  dist_vec = np.array([dist[:, k-1]])\n",
        "  sigma_mat = 2 * np.outer(dist_vec, dist_vec)\n",
        "  return sigma_mat\n",
        "\n",
        "\n",
        "def DM_coordinates(v1, v2, k):\n",
        "  distsI = euclidean_distances(v1, v1)\n",
        "  dist_matI = np.copy(distsI)\n",
        "  sigma_matI = sigma_mat(dist_matI, k)\n",
        "\n",
        "  KI = np.exp(-distsI**2 / sigma_matI)\n",
        "  KI = KI - np.diag(np.diag(KI))\n",
        "  DI = np.diag(np.sum(KI, axis=1))\n",
        "  D_leftI = np.diag(np.sum(KI,axis = 1)**-0.5)\n",
        "  D_rightI = np.diag(np.sum(KI,axis = 1)**0.5)\n",
        "  rand_walk_LI = np.matmul(np.linalg.inv(DI), KI)\n",
        "  RWL_primeI = np.matmul(D_rightI, np.matmul(rand_walk_LI, D_leftI))\n",
        "\n",
        "  eigenValuesI, eigenVectorsI = eigh(RWL_primeI)\n",
        "  idxI = eigenValuesI.argsort()[::-1]\n",
        "  d_lamI = np.diag(eigenValuesI[idxI])\n",
        "  eig_I = D_leftI@eigenVectorsI[:, idxI]\n",
        "\n",
        "  diffusion_coordinatesI = np.matmul(eig_I, d_lamI)\n",
        "  diffusion_coordinatesI_df = pd.DataFrame(diffusion_coordinatesI)\n",
        "\n",
        "  distsII = euclidean_distances(v2, v2)\n",
        "  dist_matII = np.copy(distsII)\n",
        "  sigma_matII = sigma_mat(dist_matII, k)\n",
        "\n",
        "  KII = np.exp(-distsII**2 / sigma_matII)\n",
        "  KII = KII - np.diag(np.diag(KII))\n",
        "  DII = np.diag(np.sum(KII, axis=1))\n",
        "  D_leftII = np.diag(np.sum(KII,axis = 1)**-0.5)\n",
        "  D_rightII = np.diag(np.sum(KII,axis = 1)**0.5)\n",
        "  rand_walk_LII = np.matmul(np.linalg.inv(DII), KII)\n",
        "  RWL_primeII = np.matmul(D_rightII, np.matmul(rand_walk_LII, D_leftII))\n",
        "\n",
        "  eigenValuesII, eigenVectorsII = eigh(RWL_primeII)\n",
        "  idxII = eigenValuesII.argsort()[::-1]\n",
        "  d_lamII = np.diag(eigenValuesII[idxII])\n",
        "  eig_II = D_leftII@eigenVectorsII[:, idxII]\n",
        "\n",
        "  diffusion_coordinatesII = np.matmul(eig_II, d_lamII)\n",
        "  diffusion_coordinatesII_df = pd.DataFrame(diffusion_coordinatesII)\n",
        "  return diffusion_coordinatesI_df, diffusion_coordinatesII_df\n",
        "\n",
        "\n",
        "def check_conflicts(n, eigenvec):\n",
        "  if eigenvec.shape[1] == 1:\n",
        "    x_star = eigenvec\n",
        "  else:\n",
        "    d = eigenvec.shape[1]\n",
        "    x_star = eigenvec[:, (d - 1)]\n",
        "\n",
        "  list_x = range(1, n+1)\n",
        "  list_y = range(1, n+1)\n",
        "\n",
        "  pairs = []\n",
        "  for x in list_x:\n",
        "    for y in list_y:\n",
        "      pairs.append((x, y))\n",
        "\n",
        "  df = pd.DataFrame(pairs)\n",
        "  df[\"x_star\"] = x_star\n",
        "  df.columns = [\"row_idx\", \"col_idx\", \"x_star\"]\n",
        "  df_new = df\n",
        "\n",
        "  first_point = []\n",
        "  second_point = []\n",
        "\n",
        "  for i in range(n):\n",
        "    idx = np.argmax(df_new.x_star)\n",
        "    r_idx = df_new.iloc[idx, 0]\n",
        "    first_point.append(r_idx)\n",
        "    c_idx = df_new.iloc[idx, 1]\n",
        "    second_point.append(c_idx)\n",
        "    df_new = df_new[df_new.row_idx != r_idx]\n",
        "    df_new = df_new[df_new.col_idx != c_idx]\n",
        "\n",
        "  one_to_one = pd.DataFrame(first_point)\n",
        "  one_to_one[\"second_point\"] = second_point\n",
        "  one_to_one.columns = [\"first_point\", \"second_point\"]\n",
        "  return one_to_one\n",
        "\n",
        "\n",
        "def spearman_rate(pairs, v1, v2):\n",
        "  idx1 = pairs.iloc[:,0]\n",
        "  idx1 = idx1 - 1\n",
        "  vec1 = v1.iloc[idx1,0]\n",
        "\n",
        "  idx2 = pairs.iloc[:,1]\n",
        "  idx2 = idx2 - 1\n",
        "  vec2 = v2.iloc[idx2,0]\n",
        "\n",
        "  correlation_coefficient, p_value = stats.spearmanr(vec1, vec2)\n",
        "  return correlation_coefficient\n",
        "\n",
        "\n",
        "def data_generator_path_graph(n):\n",
        "  view_1 = {'x_coord': np.sort(np.random.uniform(0, 100, n)), 'y_coord': np.repeat(1, n), 'z_coord': np.repeat(0, n)}\n",
        "  view_1 = pd.DataFrame(view_1)\n",
        "  view_2 = {'x_coord': np.sort(np.random.uniform(0, 100, n)), 'y_coord': np.repeat(-1, n), 'z_coord': np.repeat(0, n)}\n",
        "  view_2 = pd.DataFrame(view_2)\n",
        "  return view_1, view_2\n",
        "\n",
        "\n",
        "def kronecker_product2(A, B, n):\n",
        "  a_w = np.where(A != 0)\n",
        "  b_w = np.where(B != 0)\n",
        "  r_a = list(a_w[0])\n",
        "  c_a = list(a_w[1])\n",
        "  r_b = list(b_w[0])\n",
        "  c_b = list(b_w[1])\n",
        "\n",
        "  R1 = (np.outer(r_a, np.ones((1, len(r_b)))) * n).flatten() + (np.outer(np.ones((len(r_a), 1)), r_b)).flatten()\n",
        "  C1 = (np.outer(c_a, np.ones((1, len(c_b)))) * n).flatten() + (np.outer(np.ones((len(c_a), 1)), c_b)).flatten()\n",
        "  V1 = (np.outer(A[r_a, c_a].flatten(), np.ones((1, len(r_b))))) * (np.outer(np.ones((len(c_a), 1)), B[r_b, c_b].flatten()))\n",
        "  res = coo_array((V1.flatten(), (R1, C1)), shape = (n*n, n*n))\n",
        "  return res\n",
        "\n",
        "\n",
        "def compute_M2(X, Y, k):\n",
        "  x_dist = euclidean_distances(X,X)\n",
        "  idx_x = np.argpartition(x_dist, range(k))[:, k:]\n",
        "  x_dist[np.arange(idx_x.shape[0])[:,None], idx_x] = 2\n",
        "  x_dist = 2 - x_dist\n",
        "  x_dist = 0.5*(x_dist+x_dist.T)\n",
        "\n",
        "  y_dist = euclidean_distances(Y,Y)\n",
        "  idx_y = np.argpartition(y_dist, range(k))[:, k:]\n",
        "  y_dist[np.arange(idx_y.shape[0])[:,None], idx_y] = 2\n",
        "  y_dist = 2 - y_dist\n",
        "  y_dist = 0.5*(y_dist+y_dist.T)\n",
        "\n",
        "  n = x_dist.shape[0]\n",
        "  M2 = kronecker_product2(x_dist, y_dist, n)\n",
        "  return M2\n",
        "\n",
        "\n",
        "def kronecker_product3(A, B, n, sig_d = 5):\n",
        "  a_w = np.where(A != 0)\n",
        "  b_w = np.where(B != 0)\n",
        "  r_a = list(a_w[0])\n",
        "  c_a = list(a_w[1])\n",
        "  r_b = list(b_w[0])\n",
        "  c_b = list(b_w[1])\n",
        "\n",
        "  R1 = (np.outer(r_a, np.ones((1, len(r_b)))) * n).flatten() + (np.outer(np.ones((len(r_a), 1)), r_b)).flatten()\n",
        "  C1 = (np.outer(c_a, np.ones((1, len(c_b)))) * n).flatten() + (np.outer(np.ones((len(c_a), 1)), c_b)).flatten()\n",
        "  V1 = (np.outer(A[r_a, c_a].flatten(), np.ones((1, len(r_b))))) - (np.outer(np.ones((len(c_a), 1)), B[r_b, c_b].flatten()))\n",
        "  V = np.where(np.abs(V1) >= 3*sig_d, 0, (4.5 - ((V1**2)/(2*(sig_d**2)))))\n",
        "  res = coo_array((V.flatten(), (R1, C1)), shape = (n*n, n*n))\n",
        "  return res\n",
        "\n",
        "\n",
        "def compute_M3(X, Y):\n",
        "  x_dist = euclidean_distances(X,X)\n",
        "  y_dist = euclidean_distances(Y,Y)\n",
        "\n",
        "  n = x_dist.shape[0]\n",
        "  M3 = kronecker_product3(x_dist, y_dist, n)\n",
        "  return M3\n",
        "\n",
        "\n",
        "def kronecker_product4(A, B, n):\n",
        "  a_w = np.where(A != 0)\n",
        "  b_w = np.where(B != 0)\n",
        "  r_a = list(a_w[0])\n",
        "  c_a = list(a_w[1])\n",
        "  r_b = list(b_w[0])\n",
        "  c_b = list(b_w[1])\n",
        "\n",
        "  R1 = (np.outer(r_a, np.ones((1, len(r_b)))) * n).flatten() + (np.outer(np.ones((len(r_a), 1)), r_b)).flatten()\n",
        "  C1 = (np.outer(c_a, np.ones((1, len(c_b)))) * n).flatten() + (np.outer(np.ones((len(c_a), 1)), c_b)).flatten()\n",
        "  V1 = (np.outer(A[r_a, c_a].flatten(), np.ones((1, len(r_b))))) - (np.outer(np.ones((len(c_a), 1)), B[r_b, c_b].flatten()))\n",
        "  V = np.exp(-1*(V1**2))\n",
        "  res = coo_array((V.flatten(), (R1, C1)), shape = (n*n, n*n))\n",
        "  return res\n",
        "\n",
        "\n",
        "def compute_M4(X, Y):\n",
        "  x_dist = euclidean_distances(X,X)\n",
        "  y_dist = euclidean_distances(Y,Y)\n",
        "\n",
        "  n = x_dist.shape[0]\n",
        "  M4 = kronecker_product4(x_dist, y_dist, n)\n",
        "  return M4\n",
        "\n",
        "\n",
        "def get_constraint_matrix(n):\n",
        "    upper_blocks = np.zeros((n, n**2))\n",
        "    for i in range(n):\n",
        "      upper_blocks[i, i*n:((i*n)+n)] = 1\n",
        "\n",
        "    lower_blocks = np.zeros((n, n**2))\n",
        "    for j in range(n):\n",
        "      lower_blocks[:,j*n:((j*n)+n)] = np.eye(n)\n",
        "\n",
        "    A = np.vstack((upper_blocks, lower_blocks))\n",
        "    return A[:-1,:]\n",
        "\n",
        "\n",
        "def SMAC(C, b, W):\n",
        "    k = C.shape[0]\n",
        "    Ik = np.zeros((k-1, k))\n",
        "    Ik[:, :-1] = np.eye(k-1)\n",
        "    for i in range(k):\n",
        "        C[i] = C[i] - b[i]/b[-1]*C[-1]\n",
        "    Ceq = np.dot(Ik, C)\n",
        "    inv_C = np.linalg.inv(np.dot(Ceq, Ceq.T))\n",
        "    all_C = np.dot(Ceq.T, np.dot(inv_C, Ceq))\n",
        "    Pc = np.eye(C.shape[1])-all_C\n",
        "    new_W = np.dot(Pc, np.dot(W, Pc))\n",
        "    eValue, eVector = eigsh(new_W, k=1)\n",
        "    return eVector\n",
        "\n",
        "\n",
        "def SDP_relax(W, n):\n",
        "    \"\"\"\n",
        "    :param W: Compatibility matrix\n",
        "    :param n: size the graphs\n",
        "    :return: optimal x\n",
        "    \"\"\"\n",
        "    d = np.diag(W)\n",
        "    Weq = np.zeros((W.shape[0]+1, W.shape[1]+1))\n",
        "    Weq[0, 1:] = d/2\n",
        "    Weq[1:, 0] = d/2\n",
        "    Weq[1:, 1:] = W-np.diag(d)\n",
        "\n",
        "    c, A = [], []\n",
        "\n",
        "    # First condition: X[0, 0] = 1\n",
        "    A_11 = np.zeros(Weq.shape)\n",
        "    A_11[0, 0] = 1\n",
        "    c.append(1), A.append(A_11)\n",
        "\n",
        "    # Second condition: weak enforcement of x_i = x_i^2\n",
        "    for i in range(1, W.shape[0]+1):\n",
        "        Ai = np.zeros(Weq.shape)\n",
        "        Ai[0, i] = -1\n",
        "        Ai[i, 0] = -1\n",
        "        Ai[i, i] = 2\n",
        "        c.append(0), A.append(Ai)\n",
        "\n",
        "    # Conditions of Sum_{j}(x_i*n+j) for all i, same for columns\n",
        "    for s in range(n):\n",
        "        As = np.zeros(Weq.shape)\n",
        "        Asp = np.zeros(Weq.shape)\n",
        "        As[n*s+1:n*(s+1)+1, n*s+1:n*(s+1)+1] = np.eye(n)\n",
        "        for t in range(n):\n",
        "            Asp[n*t+s+1, n*t+s+1] = 1\n",
        "        c.append(1), A.append(As)\n",
        "        c.append(1), A.append(Asp)\n",
        "\n",
        "    X = Variable(shape=(n**2+1, n**2+1), PSD=True)\n",
        "    obj = Maximize(trace(Weq*X))\n",
        "    constraints = []\n",
        "    for ci, Ai in zip(c, A):\n",
        "        constraints.append(trace(matmul(Ai, X))==ci)\n",
        "    prob = Problem(obj, constraints)\n",
        "    prob.solve(SCS)\n",
        "    if prob.status != 'optimal':\n",
        "        print('CVXPY failed to reach optimal value')\n",
        "    return np.diag(X.value)[1:]"
      ],
      "metadata": {
        "id": "yR3R_-hEiLd-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_M2_new(X, Y, k):\n",
        "  x_dist = euclidean_distances(X,X)\n",
        "  idx_x = np.argpartition(x_dist, range(k))[:, k:]\n",
        "  x_dist[np.arange(idx_x.shape[0])[:,None], idx_x] = 2\n",
        "  x_dist = 2 - x_dist\n",
        "  Q_x = 0.5*(x_dist+x_dist.T)\n",
        "\n",
        "  y_dist = euclidean_distances(Y,Y)\n",
        "  idx_y = np.argpartition(y_dist, range(k))[:, k:]\n",
        "  y_dist[np.arange(idx_y.shape[0])[:,None], idx_y] = 2\n",
        "  y_dist = 2 - y_dist\n",
        "  Q_y = 0.5*(y_dist+y_dist.T)\n",
        "\n",
        "  return Q_x, Q_y"
      ],
      "metadata": {
        "id": "wU3r3qtJs4XW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def matching_rate_M2_mixed_CC(n, k, n_col, num_coords, M, data_func, *args):\n",
        "  st = time.time()\n",
        "\n",
        "  num_ev = []\n",
        "  cor_lst = []\n",
        "  cor_lst1 = []\n",
        "  cor_lst2 = []\n",
        "  cor_lst3 = []\n",
        "  cor_lst4 = []\n",
        "  cor_lst5 = []\n",
        "  cor_lst6 = []\n",
        "  cor_lst7 = []\n",
        "  cor_lst8 = []\n",
        "  cor_lst9 = []\n",
        "\n",
        "  for i in range(M):\n",
        "    print(i)\n",
        "    view_1, view_2 = data_func(*args)\n",
        "    view1 = view_1.iloc[:,0:n_col]\n",
        "    view2 = view_2.iloc[:,0:n_col]\n",
        "\n",
        "    diffusion_coordinatesI_df, diffusion_coordinatesII_df = DM_coordinates(view1, view2, k)\n",
        "\n",
        "    leadEV1 = diffusion_coordinatesI_df.iloc[:,1:num_coords]\n",
        "    leadEV2 = diffusion_coordinatesII_df.iloc[:,1:num_coords]\n",
        "\n",
        "    norm_view1 = normalize(leadEV1, axis=1, norm='l2')\n",
        "    norm_view2 = normalize(leadEV2, axis=1, norm='l2')\n",
        "\n",
        "    Q_1, Q_2 = compute_M2_new(norm_view1, norm_view2, k)\n",
        "    e_val_Q1, e_vec_Q1 = eigsh(Q_1, k=3)\n",
        "    e_val_Q2, e_vec_Q2 = eigsh(Q_2, k=3)\n",
        "\n",
        "    V = []\n",
        "    for i in range(3):\n",
        "      for j in range(3):\n",
        "        V.append(np.reshape(np.outer(e_vec_Q1[:,i],e_vec_Q2[:,j]),(n**2)))\n",
        "\n",
        "    eVector1 = V[8]\n",
        "    eVector2 = V[7]\n",
        "    eVector3 = V[6]\n",
        "    eVector4 = V[5]\n",
        "    eVector5 = V[4]\n",
        "    eVector6 = V[3]\n",
        "    eVector7 = V[2]\n",
        "    eVector8 = V[1]\n",
        "    eVector9 = V[0]\n",
        "\n",
        "    pairs1 = check_conflicts(n, eVector1.reshape(n*n, 1))\n",
        "    pairs2 = check_conflicts(n, eVector2.reshape(n*n, 1))\n",
        "    pairs3 = check_conflicts(n, eVector3.reshape(n*n, 1))\n",
        "    pairs4 = check_conflicts(n, eVector4.reshape(n*n, 1))\n",
        "    pairs5 = check_conflicts(n, eVector5.reshape(n*n, 1))\n",
        "    pairs6 = check_conflicts(n, eVector6.reshape(n*n, 1))\n",
        "    pairs7 = check_conflicts(n, eVector7.reshape(n*n, 1))\n",
        "    pairs8 = check_conflicts(n, eVector8.reshape(n*n, 1))\n",
        "    pairs9 = check_conflicts(n, eVector9.reshape(n*n, 1))\n",
        "\n",
        "    s1 = spearman_rate(pairs1, view_1, view_2)\n",
        "    cor_lst1.append(s1)\n",
        "    s2 = spearman_rate(pairs2, view_1, view_2)\n",
        "    cor_lst2.append(s2)\n",
        "    s3 = spearman_rate(pairs3, view_1, view_2)\n",
        "    cor_lst3.append(s3)\n",
        "    s4 = spearman_rate(pairs4, view_1, view_2)\n",
        "    cor_lst4.append(s4)\n",
        "    s5 = spearman_rate(pairs5, view_1, view_2)\n",
        "    cor_lst5.append(s5)\n",
        "    s6 = spearman_rate(pairs6, view_1, view_2)\n",
        "    cor_lst6.append(s6)\n",
        "    s7 = spearman_rate(pairs7, view_1, view_2)\n",
        "    cor_lst7.append(s7)\n",
        "    s8 = spearman_rate(pairs8, view_1, view_2)\n",
        "    cor_lst8.append(s8)\n",
        "    s9 = spearman_rate(pairs9, view_1, view_2)\n",
        "    cor_lst9.append(s9)\n",
        "\n",
        "    v1 = np.zeros((n*n,1))\n",
        "    n_pairs1 = pairs1.sort_values('first_point')\n",
        "    for i in range(n):\n",
        "      d1 = n_pairs1.iloc[i,1]\n",
        "      idx1 = (n*i) + d1-1\n",
        "      v1[idx1] = 1\n",
        "    P_v1 = v1.reshape(n, n)\n",
        "    result_matrix1 = Q_2 @ P_v1 @ Q_1.T @ P_v1.T\n",
        "    obj_res1 = np.trace(result_matrix1)\n",
        "\n",
        "    v2 = np.zeros((n*n,1))\n",
        "    n_pairs2 = pairs2.sort_values('first_point')\n",
        "    for i in range(n):\n",
        "      d2 = n_pairs2.iloc[i,1]\n",
        "      idx2 = (n*i) + d2-1\n",
        "      v2[idx2] = 1\n",
        "    P_v2 = v2.reshape(n, n)\n",
        "    result_matrix2 = Q_2 @ P_v2 @ Q_1.T @ P_v2.T\n",
        "    obj_res2 = np.trace(result_matrix2)\n",
        "\n",
        "    v3 = np.zeros((n*n,1))\n",
        "    n_pairs3 = pairs3.sort_values('first_point')\n",
        "    for i in range(n):\n",
        "      d3 = n_pairs3.iloc[i,1]\n",
        "      idx3 = (n*i) + d3-1\n",
        "      v3[idx3] = 1\n",
        "    P_v3 = v3.reshape(n, n)\n",
        "    result_matrix3 = Q_2 @ P_v3 @ Q_1.T @ P_v3.T\n",
        "    obj_res3 = np.trace(result_matrix3)\n",
        "\n",
        "    v4 = np.zeros((n*n,1))\n",
        "    n_pairs4 = pairs4.sort_values('first_point')\n",
        "    for i in range(n):\n",
        "      d4 = n_pairs4.iloc[i,1]\n",
        "      idx4 = (n*i) + d4-1\n",
        "      v4[idx4] = 1\n",
        "    P_v4 = v4.reshape(n, n)\n",
        "    result_matrix4 = Q_2 @ P_v4 @ Q_1.T @ P_v4.T\n",
        "    obj_res4 = np.trace(result_matrix4)\n",
        "\n",
        "    v5 = np.zeros((n*n,1))\n",
        "    n_pairs5 = pairs5.sort_values('first_point')\n",
        "    for i in range(n):\n",
        "      d5 = n_pairs5.iloc[i,1]\n",
        "      idx5 = (n*i) + d5-1\n",
        "      v5[idx5] = 1\n",
        "    P_v5 = v5.reshape(n, n)\n",
        "    result_matrix5 = Q_2 @ P_v5 @ Q_1.T @ P_v5.T\n",
        "    obj_res5 = np.trace(result_matrix5)\n",
        "\n",
        "    v6 = np.zeros((n*n,1))\n",
        "    n_pairs6 = pairs6.sort_values('first_point')\n",
        "    for i in range(n):\n",
        "      d6 = n_pairs6.iloc[i,1]\n",
        "      idx6 = (n*i) + d6-1\n",
        "      v6[idx6] = 1\n",
        "    P_v6 = v6.reshape(n, n)\n",
        "    result_matrix6 = Q_2 @ P_v6 @ Q_1.T @ P_v6.T\n",
        "    obj_res6 = np.trace(result_matrix6)\n",
        "\n",
        "    v7 = np.zeros((n*n,1))\n",
        "    n_pairs7 = pairs7.sort_values('first_point')\n",
        "    for i in range(n):\n",
        "      d7 = n_pairs7.iloc[i,1]\n",
        "      idx7 = (n*i) + d7-1\n",
        "      v7[idx7] = 1\n",
        "    P_v7 = v7.reshape(n, n)\n",
        "    result_matrix7 = Q_2 @ P_v7 @ Q_1.T @ P_v7.T\n",
        "    obj_res7 = np.trace(result_matrix7)\n",
        "\n",
        "    v8 = np.zeros((n*n,1))\n",
        "    n_pairs8 = pairs8.sort_values('first_point')\n",
        "    for i in range(n):\n",
        "      d8 = n_pairs8.iloc[i,1]\n",
        "      idx8 = (n*i) + d8-1\n",
        "      v8[idx8] = 1\n",
        "    P_v8 = v8.reshape(n, n)\n",
        "    result_matrix8 = Q_2 @ P_v8 @ Q_1.T @ P_v8.T\n",
        "    obj_res8 = np.trace(result_matrix8)\n",
        "\n",
        "    v9 = np.zeros((n*n,1))\n",
        "    n_pairs9 = pairs9.sort_values('first_point')\n",
        "    for i in range(n):\n",
        "      d9 = n_pairs9.iloc[i,1]\n",
        "      idx9 = (n*i) + d9-1\n",
        "      v9[idx9] = 1\n",
        "    P_v9 = v9.reshape(n, n)\n",
        "    result_matrix9 = Q_2 @ P_v9 @ Q_1.T @ P_v9.T\n",
        "    obj_res9 = np.trace(result_matrix9)\n",
        "\n",
        "    obj_arr = np.array([float(obj_res1), float(obj_res2), float(obj_res3), float(obj_res4), float(obj_res5), float(obj_res6), float(obj_res7), float(obj_res8), float(obj_res9)])\n",
        "    idx = np.argmax(obj_arr)\n",
        "    max = np.max(obj_arr)\n",
        "    print(\"The result - ev number \" + str((idx+1)) + \", objective function = \" + str(round(max, 3)))\n",
        "\n",
        "    s_arr = np.array([float(s1), float(s2), float(s3), float(s4), float(s5), float(s6), float(s7), float(s8), float(s9)])\n",
        "    cor_lst.append(s_arr[idx])\n",
        "    num_ev.append(idx+1)\n",
        "\n",
        "  et = time.time()\n",
        "\n",
        "  total_time = et - st\n",
        "  print(\"Execution time of matching_rate: \", total_time, \" seconds\")\n",
        "\n",
        "  return pairs1, pairs2, pairs3, pairs4, pairs5, pairs6, pairs7, pairs8, pairs9, view_1, view_2, cor_lst1, cor_lst2, cor_lst3, cor_lst4, cor_lst5, cor_lst6, cor_lst7, cor_lst8, cor_lst9, num_ev, cor_lst"
      ],
      "metadata": {
        "id": "czuUSMr2iOfh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_lst = [50, 60, 70, 80, 90, 100, 120, 150]\n",
        "\n",
        "l = len(n_lst)\n",
        "num_coords = 4\n",
        "n_col = 1\n",
        "\n",
        "st = time.time()\n",
        "\n",
        "def GM_sys_M2_mixed_CC(ns, M, num_coords, n_col):\n",
        "  num_nodes = []\n",
        "  run_time = []\n",
        "  num_evs = []\n",
        "\n",
        "  median_spe_M = []\n",
        "  median_spe_M_1 = []\n",
        "  median_spe_M_2 = []\n",
        "  median_spe_M_3 = []\n",
        "\n",
        "  mean_spe_M = []\n",
        "  mean_spe_M_1 = []\n",
        "  mean_spe_M_2 = []\n",
        "  mean_spe_M_3 = []\n",
        "\n",
        "  std_spe_M = []\n",
        "  std_spe_M_1 = []\n",
        "  std_spe_M_2 = []\n",
        "  std_spe_M_3 = []\n",
        "\n",
        "  for i in range(l):\n",
        "    print(i)\n",
        "    num_nodes.append(ns[i])\n",
        "    st = time.time()\n",
        "    k_neigh = 15\n",
        "\n",
        "    pairs1, pairs2, pairs3, pairs4, pairs5, pairs6, pairs7, pairs8, pairs9, view_1, view_2, cor_lst1, cor_lst2, cor_lst3, cor_lst4, cor_lst5, cor_lst6, cor_lst7, cor_lst8, cor_lst9, num_ev, cor_lst = matching_rate_M2_mixed_CC(ns[i], k_neigh, n_col, num_coords, M, data_generator_path_graph, ns[i])\n",
        "    et = time.time()\n",
        "    total_time = et - st\n",
        "    run_time.append(total_time)\n",
        "    num_evs.append(num_ev)\n",
        "\n",
        "    # M\n",
        "    median_spe_M.append(np.median(np.abs(cor_lst)))\n",
        "    mean_spe_M.append(np.mean(np.abs(cor_lst)))\n",
        "    std_spe_M.append(np.std(np.abs(cor_lst)))\n",
        "\n",
        "    median_spe_M_1.append(np.median(np.abs(cor_lst1)))\n",
        "    mean_spe_M_1.append(np.mean(np.abs(cor_lst1)))\n",
        "    std_spe_M_1.append(np.std(np.abs(cor_lst1)))\n",
        "\n",
        "    median_spe_M_2.append(np.median(np.abs(cor_lst2)))\n",
        "    mean_spe_M_2.append(np.mean(np.abs(cor_lst2)))\n",
        "    std_spe_M_2.append(np.std(np.abs(cor_lst2)))\n",
        "\n",
        "    median_spe_M_3.append(np.median(np.abs(cor_lst3)))\n",
        "    mean_spe_M_3.append(np.mean(np.abs(cor_lst3)))\n",
        "    std_spe_M_3.append(np.std(np.abs(cor_lst3)))\n",
        "\n",
        "  return num_nodes, run_time, median_spe_M_1, median_spe_M_2, median_spe_M_3, mean_spe_M_1, mean_spe_M_2, mean_spe_M_3, std_spe_M_1, std_spe_M_2, std_spe_M_3, num_evs, median_spe_M, mean_spe_M, std_spe_M\n",
        "\n",
        "et = time.time()\n",
        "total_time = et - st\n",
        "print(\"Execution time: \", total_time, \" seconds\")\n",
        "\n",
        "m = 25\n",
        "num_nodes, run_time, median_spe_M_1, median_spe_M_2, median_spe_M_3, mean_spe_M_1, mean_spe_M_2, mean_spe_M_3, std_spe_M_1, std_spe_M_2, std_spe_M_3, num_evs, median_spe_M, mean_spe_M, std_spe_M = GM_sys_M2_mixed_CC(n_lst, m, num_coords, n_col)"
      ],
      "metadata": {
        "id": "Ntwy8JCwiRvY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True) # Force remount to refresh credentials\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4WnL84CV4_ft",
        "outputId": "57cc763f-c035-4e08-f0a6-fff664a83f0e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Nofar-Gabay-30/Unsupervised-Data-Fusion-Via-Graph-Matching.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I028uPiT2ccU",
        "outputId": "061bde3c-de9a-4d63-a27e-d1a22ba35e3b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Unsupervised-Data-Fusion-Via-Graph-Matching'...\n",
            "warning: You appear to have cloned an empty repository.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp \"/content/drive/MyDrive/Unsupervised Data Fusion Via Graph Matching - Path Graph.ipynb\" \"/content/Unsupervised Data Fusion Via Graph Matching/\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "irDjr8_G3AsF",
        "outputId": "eadaae85-3d05-4f79-f244-720f4dfb4eac"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: cannot stat '/content/drive/MyDrive/Unsupervised Data Fusion Via Graph Matching - Path Graph.ipynb': No such file or directory\n"
          ]
        }
      ]
    }
  ]
}